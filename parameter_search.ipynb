{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data20241116c.csv\")\n",
    "\n",
    "# Split the data\n",
    "X = df.drop(columns=['demand','timestamp','Unnamed: 0'])\n",
    "y = df['demand']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "categorical_features = ['hour_of_day', 'day_of_week','day_of_month','month_of_year']\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train,enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test,enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters: {'subsample': 0.6, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n",
      "Test RMSE: 1.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Define parameter grid for RandomizedSearch\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of parameter settings sampled\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Test RMSE: 1.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a smaller parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5],\n",
    "    'min_child_weight': [1, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-17 20:24:53,281] A new study created in memory with name: no-name-5371f5e9-a2ed-46d7-bb32-56a6c24099e5\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:53,368] Trial 0 finished with value: 1.6652731079460816 and parameters: {'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.7736707893542558, 'colsample_bytree': 0.8163892149081823, 'learning_rate': 0.06080470563035991, 'n_estimators': 220}. Best is trial 0 with value: 1.6652731079460816.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:53,513] Trial 1 finished with value: 1.5208791990383654 and parameters: {'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.672443135851356, 'colsample_bytree': 0.8149424850492875, 'learning_rate': 0.021325884379183632, 'n_estimators': 292}. Best is trial 1 with value: 1.5208791990383654.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:53,725] Trial 2 finished with value: 1.6264852422663976 and parameters: {'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.6925544989094734, 'colsample_bytree': 0.7230435402357784, 'learning_rate': 0.09385659935334784, 'n_estimators': 250}. Best is trial 1 with value: 1.5208791990383654.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:53,862] Trial 3 finished with value: 1.4319059809365433 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.5320328816423274, 'colsample_bytree': 0.7969344736374335, 'learning_rate': 0.03416647981364684, 'n_estimators': 211}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:54,030] Trial 4 finished with value: 1.5412338640096523 and parameters: {'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.7278782946704339, 'colsample_bytree': 0.7321893096973491, 'learning_rate': 0.012646411952043924, 'n_estimators': 232}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:54,154] Trial 5 finished with value: 1.5561377399594558 and parameters: {'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.6030801686291225, 'colsample_bytree': 0.7791168894578259, 'learning_rate': 0.06561903994442726, 'n_estimators': 139}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:54,343] Trial 6 finished with value: 1.5445168869967258 and parameters: {'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.6648116313314105, 'colsample_bytree': 0.5549003753009338, 'learning_rate': 0.04070632880580003, 'n_estimators': 231}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:54,436] Trial 7 finished with value: 1.6562279354996703 and parameters: {'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.5769282414373906, 'colsample_bytree': 0.8223679073710106, 'learning_rate': 0.1722142800173908, 'n_estimators': 138}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:54,596] Trial 8 finished with value: 1.5419280282950347 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.5415684933960069, 'colsample_bytree': 0.8312492072624611, 'learning_rate': 0.01271048333877809, 'n_estimators': 275}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:54,865] Trial 9 finished with value: 1.464029623854864 and parameters: {'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7196802656841789, 'colsample_bytree': 0.5265834780543408, 'learning_rate': 0.0143320372666084, 'n_estimators': 283}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:55,060] Trial 10 finished with value: 1.4750551760419017 and parameters: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9462146137096356, 'colsample_bytree': 0.9880380353901039, 'learning_rate': 0.02927975391899853, 'n_estimators': 167}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:55,194] Trial 11 finished with value: 1.4836926816932037 and parameters: {'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.8420415309810692, 'colsample_bytree': 0.5393383035985893, 'learning_rate': 0.022046635569108054, 'n_estimators': 186}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:55,430] Trial 12 finished with value: 1.48134313725232 and parameters: {'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.5142766160060208, 'colsample_bytree': 0.640828803237647, 'learning_rate': 0.018802767035691958, 'n_estimators': 271}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:55,514] Trial 13 finished with value: 2.7806376964605195 and parameters: {'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.843175125030628, 'colsample_bytree': 0.9336818819175356, 'learning_rate': 0.010474023496009786, 'n_estimators': 101}. Best is trial 3 with value: 1.4319059809365433.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:55,727] Trial 14 finished with value: 1.3422410983133028 and parameters: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9972621730657976, 'colsample_bytree': 0.6429678916412152, 'learning_rate': 0.03567325422386057, 'n_estimators': 194}. Best is trial 14 with value: 1.3422410983133028.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:55,907] Trial 15 finished with value: 1.3646200650574676 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.9390133375582612, 'colsample_bytree': 0.6147710803408114, 'learning_rate': 0.037233088613638395, 'n_estimators': 193}. Best is trial 14 with value: 1.3422410983133028.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:56,106] Trial 16 finished with value: 1.3699939821604539 and parameters: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.99584552292655, 'colsample_bytree': 0.631980871087697, 'learning_rate': 0.05082409182277037, 'n_estimators': 184}. Best is trial 14 with value: 1.3422410983133028.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:56,242] Trial 17 finished with value: 1.523173339304101 and parameters: {'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.9172406654563102, 'colsample_bytree': 0.6292813742558544, 'learning_rate': 0.10738170462784327, 'n_estimators': 157}. Best is trial 14 with value: 1.3422410983133028.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:56,372] Trial 18 finished with value: 1.4264878427355154 and parameters: {'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.9049530120145259, 'colsample_bytree': 0.6814746951018555, 'learning_rate': 0.02973180715476242, 'n_estimators': 192}. Best is trial 14 with value: 1.3422410983133028.\n",
      "C:\\Users\\kevinkang\\AppData\\Local\\Temp\\ipykernel_17904\\1375528138.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "[I 2024-11-17 20:24:56,662] Trial 19 finished with value: 1.427525119203688 and parameters: {'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9871980527904359, 'colsample_bytree': 0.5851700152740404, 'learning_rate': 0.0735881150800471, 'n_estimators': 250}. Best is trial 14 with value: 1.3422410983133028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9972621730657976, 'colsample_bytree': 0.6429678916412152, 'learning_rate': 0.03567325422386057, 'n_estimators': 194}\n",
      "Best RMSE: 1.3422410983133028\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300)\n",
    "    }\n",
    "    \n",
    "    # Define the XGBoost model\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', **params)\n",
    "    \n",
    "    # Train and evaluate using cross-validation\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "# Set up and run the Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Display the best parameters and score\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
